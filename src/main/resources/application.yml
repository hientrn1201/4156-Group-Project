spring:
  application:
    name: knowledge-management-service

  datasource:
    url: jdbc:postgresql://localhost:5432/knowledge_db
    username: postgres
    password: postgres
    driver-class-name: org.postgresql.Driver

  jpa:
    hibernate:
      ddl-auto: update
    show-sql: true
    properties:
      hibernate:
        dialect: org.hibernate.dialect.PostgreSQLDialect

  servlet:
    multipart:
      max-file-size: 50MB
      max-request-size: 50MB

  # Docker Compose Configuration
  docker:
    compose:
      lifecycle-management: start-and-stop
      enabled: true
      file: docker-compose.yml

  # Spring AI Configuration
  ai:
    ollama:
      base-url: http://localhost:11434/
      chat:
        options:
          model: llama3.2
          temperature: 0.7
      embedding:
        options:
          model: llama3.2
    vectorstore:
      pgvector:
        initialize-schema: true
        remove-existing-vector-store-table: true
        index-type: HNSW
        distance-type: COSINE_DISTANCE

server:
  port: 8080

logging:
  level:
    dev.coms4156.project: INFO
    API_LOGS: INFO
    org.hibernate.SQL: DEBUG
    org.springframework.ai: DEBUG
  pattern:
    console: "%d{yyyy-MM-dd HH:mm:ss.SSS} [%thread] %-5level %logger{36} - %msg%n"
    file: "%d{yyyy-MM-dd HH:mm:ss.SSS} [%thread] %-5level %logger{36} - %msg%n"
  file:
    name: logs/api-logs.log
  logback:
    rollingpolicy:
      max-file-size: 10MB
      max-history: 30
      total-size-cap: 1GB

# Custom application properties
app:
  document:
    chunk-size: 1000
    chunk-overlap: 200
    max-file-size: 50MB
  vector:
    dimensions: 4096  # llama3.2 produces 4096-dimensional embeddings
    similarity-threshold: 0.7
  summarization:
    max-summary-length: 500